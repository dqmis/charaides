{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, ImageDraw \n",
    "import os\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import ast\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models'\n",
    "model_ = '{}/doodle_model1570758141_19.pt'.format(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module that defines function that trains the model.\n",
    "\"\"\"\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "def fit(dataloader, model, criterion, optimizer, scheduler=None, num_epochs=25):\n",
    "    \"\"\"\n",
    "    This function trains the model passed by the arguments.\n",
    "    Parameters:\n",
    "        dataloader(dict): Dict that keeps train and val data.\n",
    "        model(torchvision.models): Model to train.\n",
    "        criterion(torch.nn.modules.loss): Defined training loss.\n",
    "        optimizer(torch.optim): Optimizer.\n",
    "        device(torch.device): Device representer where Tensors will be allocated.\n",
    "        num_epochs(int): Number of epochs to train the model.\n",
    "    Returns:\n",
    "        model(torchvision.models): Trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for batch in dataloader[phase]:\n",
    "                inputs = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if scheduler is not None:\n",
    "                            scheduler.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == torch.max(labels, 1)[1])\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            if phase == 'train':\n",
    "                torch.save(model.state_dict(), '{}/doodle_model{}_{}.pt'.format(model_path, int(time.time()), epoch))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def predict(dataset, model, topk=2):\n",
    "    \"\"\"\n",
    "    This function predicts the labels for given dataset.\n",
    "    Parameters:\n",
    "        dataset(torch.utils.data.Dataloader): Dataloader that keeps the data to predict on.\n",
    "        model(torchvision.models): Model to make predictions with.\n",
    "        top_k(int): Top_k predictions to make.\n",
    "    Returns:\n",
    "        (dict): Dictionary with cofidence score, one_hot prediction vector and top_k predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    one_hot = []\n",
    "    confidence = []\n",
    "    top_k = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            images = data['image'].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            top_k.extend(torch.topk(outputs.data, topk).indices.cpu().tolist())\n",
    "            one_hot.extend(torch.nn.functional.one_hot(predicted).cpu().tolist())\n",
    "            confidence.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().tolist())\n",
    "    return {'confidence': confidence, 'one_hot': one_hot, 'top_k': top_k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir('./csv_data')[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoodleDataset(Dataset):\n",
    "    \n",
    "    def draw_it(self, strokes):\n",
    "        image = Image.new(\"P\", (256,256), color=255)\n",
    "        image_draw = ImageDraw.Draw(image)\n",
    "        for stroke in ast.literal_eval(strokes):\n",
    "            for i in range(len(stroke[0])-1):\n",
    "                image_draw.line([stroke[0][i], \n",
    "                                 stroke[1][i],\n",
    "                                 stroke[0][i+1], \n",
    "                                 stroke[1][i+1]],\n",
    "                                fill=0, width=5)\n",
    "        return image.convert('RGB')\n",
    "    \n",
    "    def get_df(self, source_dir, class_list, im_per_class):\n",
    "        li = []\n",
    "        for class_ in class_list:\n",
    "            df = pd.read_csv('{}/{}'.format(source_dir, class_),\n",
    "                             engine='python',\n",
    "                             usecols=['drawing', 'recognized', 'word'],\n",
    "                             nrows=im_per_class*5//4)\n",
    "            df = df[df.recognized == True][['drawing', 'word']]\n",
    "            li.append(df.head(im_per_class))\n",
    "        return pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "    def __init__(self, source_dir, class_list=[], im_size=224, im_per_class=3000, transform=None):\n",
    "        self.transform = transform\n",
    "        self.im_size = im_size\n",
    "        self.source_dir = source_dir\n",
    "        if len(class_list) < 1:\n",
    "            self.class_list = os.listdir(self.source_dir)\n",
    "        else:\n",
    "            self.class_list = class_list\n",
    "        self.source_df = self.get_df(self.source_dir, self.class_list, im_per_class)\n",
    "        self.one_hot_labels = pd.get_dummies(self.source_df['word'])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.source_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        class_name = self.source_df.iloc[idx, 1]\n",
    "        label = torch.LongTensor(self.one_hot_labels.iloc[idx].values)\n",
    "        image = self.draw_it(self.source_df.iloc[idx, 0])\n",
    "        sample = {'image': image, 'label': label, 'class_name': class_name}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = DoodleDataset('./csv_data', class_list=os.listdir('./csv_data')[:50], im_per_class=5000)\n",
    "\n",
    "# Splitting the data \n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "test_size = int(0.2 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size - test_size\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, test_size, val_size]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.255]\n",
    ")\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.dataset.transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "test_dataset.dataset.transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_dataset.dataset.transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataloader = {\n",
    "    'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False),\n",
    "    'test': DataLoader(test_dataset, batch_size=batch_size, shuffle=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.axis('off')\n",
    "    # Here I am using inverse normalization to display augmented images.\n",
    "    plt.imshow(transforms.ToPILImage()(inv_normalize(sample['image'])))\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading the Resnet18 with pretrained weights and freezing the models layers.\n",
    "\n",
    "if model_:\n",
    "    model = torchvision.models.resnet50(pretrained=False)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(model_))\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Adding FC layer to train classifier. Required_grad is true by default here.\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "# Setting loss and optimizer. I chose Cross Entropy Loss because it is moustly used loss function when\n",
    "# training for multiclass classification. Adam is also just state of the art optimization algorithm.\n",
    "# It has its downsides but in my opinion still a better choice here than a SGD.\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit(dataloader, model, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './doodle.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
